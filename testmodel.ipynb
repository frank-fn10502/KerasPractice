{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my custom lib\n",
    "from basicModel import LeNet\n",
    "from basicModel import AlexNet\n",
    "\n",
    "\n",
    "from small_dataset import MNIST\n",
    "from small_dataset import CIFAR10\n",
    "from small_dataset import CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_6650/2113591372.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 02:24:33.165578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2851 MB memory:  -> device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "2021-10-13 02:24:33.167535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:1 with 2851 MB memory:  -> device: 1, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2021-10-13 02:24:33.169401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:2 with 2849 MB memory:  -> device: 2, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "2021-10-13 02:24:33.171277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:3 with 2849 MB memory:  -> device: 3, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "2021-10-13 02:24:33.173132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:4 with 2849 MB memory:  -> device: 4, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:85:00.0, compute capability: 6.1\n",
      "2021-10-13 02:24:33.174957: I tensorflow/core/common_runtime/gpu/gpu_device."
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cc:1510] Created device /device:GPU:5 with 2849 MB memory:  -> device: 5, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:86:00.0, compute capability: 6.1\n",
      "2021-10-13 02:24:33.176790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:6 with 2851 MB memory:  -> device: 6, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:89:00.0, compute capability: 6.1\n",
      "2021-10-13 02:24:33.178656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:7 with 2851 MB memory:  -> device: 7, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:8a:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n",
    "# tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: \n",
      "    使用 tensorflow.keras 取得的 CIFAR10 資料集(https://keras.io/api/datasets/cifar10/) \n",
      "\n",
      "    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. \n",
      "\n",
      "    There are 50000 training images and 10000 test images.\n",
      "     \n",
      "\n",
      "one-hot encoder:\n",
      "\tindex: 0 ,pre: [6] ,after:[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "\tindex: 0 ,pre: [3] ,after:[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "----------\n",
      "train_x:(50000, 32, 32, 3) \n",
      "train_y:(50000, 10) \n",
      "test_x:(10000, 32, 32, 3) \n",
      "test_y:(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(info=True).addChannel().tocategorical().Done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"frank_AlexNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "rescaling_2 (Rescaling)      (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "resizing_2 (Resizing)        (None, 227, 227, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 6, 6, 256)         884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 24,769,290\n",
      "Trainable params: 24,768,586\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "drawModelImg... Done\n",
      "saveModelTxT... Done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#取得模型架構\n",
    "MyNet = AlexNet(datasetName=dataset.className,input_shape=(32,32,3) ,classes=len(dataset.train_y[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 01:34:56.765085: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 01:34:58.245058: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 25s 28ms/step - loss: 2.2256 - accuracy: 0.1678 - val_loss: 2.0205 - val_accuracy: 0.2910\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.9837 - accuracy: 0.2639 - val_loss: 1.8187 - val_accuracy: 0.3530\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.8450 - accuracy: 0.3134 - val_loss: 1.7002 - val_accuracy: 0.3935\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.7411 - accuracy: 0.3497 - val_loss: 1.6058 - val_accuracy: 0.4243\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.6543 - accuracy: 0.3839 - val_loss: 1.5313 - val_accuracy: 0.4515\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.5889 - accuracy: 0.4091 - val_loss: 1.4748 - val_accuracy: 0.4630\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.5332 - accuracy: 0.4346 - val_loss: 1.4277 - val_accuracy: 0.4837\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.4871 - accuracy: 0.4512 - val_loss: 1.3860 - val_accuracy: 0.4977\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.4494 - accuracy: 0.4659 - val_loss: 1.3516 - val_accuracy: 0.5087\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 1.4108 - accuracy: 0.4853 - val_loss: 1.3231 - val_accuracy: 0.5190\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.3802 - accuracy: 0.4949 - val_loss: 1.3005 - val_accuracy: 0.5269\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.3543 - accuracy: 0.5069 - val_loss: 1.2725 - val_accuracy: 0.5372\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.3283 - accuracy: 0.5175 - val_loss: 1.2565 - val_accuracy: 0.5430\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.3037 - accuracy: 0.5270 - val_loss: 1.2337 - val_accuracy: 0.5526\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.2827 - accuracy: 0.5338 - val_loss: 1.2138 - val_accuracy: 0.5610\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.2626 - accuracy: 0.5459 - val_loss: 1.1980 - val_accuracy: 0.5695\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.2441 - accuracy: 0.5493 - val_loss: 1.1824 - val_accuracy: 0.5731\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.2269 - accuracy: 0.5569 - val_loss: 1.1690 - val_accuracy: 0.5810\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.2079 - accuracy: 0.5641 - val_loss: 1.1565 - val_accuracy: 0.5863\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.1905 - accuracy: 0.5731 - val_loss: 1.1405 - val_accuracy: 0.5910\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.1808 - accuracy: 0.5770 - val_loss: 1.1286 - val_accuracy: 0.5963\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.1648 - accuracy: 0.5823 - val_loss: 1.1170 - val_accuracy: 0.5992\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.1520 - accuracy: 0.5872 - val_loss: 1.1094 - val_accuracy: 0.6055\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.1405 - accuracy: 0.5913 - val_loss: 1.0998 - val_accuracy: 0.6064\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.1290 - accuracy: 0.5978 - val_loss: 1.0901 - val_accuracy: 0.6122\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.1163 - accuracy: 0.6015 - val_loss: 1.0807 - val_accuracy: 0.6116\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.1038 - accuracy: 0.6069 - val_loss: 1.0709 - val_accuracy: 0.6197\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0972 - accuracy: 0.6070 - val_loss: 1.0623 - val_accuracy: 0.6210\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0851 - accuracy: 0.6134 - val_loss: 1.0594 - val_accuracy: 0.6212\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0806 - accuracy: 0.6161 - val_loss: 1.0556 - val_accuracy: 0.6245\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0705 - accuracy: 0.6177 - val_loss: 1.0461 - val_accuracy: 0.6290\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0635 - accuracy: 0.6223 - val_loss: 1.0374 - val_accuracy: 0.6314\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0556 - accuracy: 0.6237 - val_loss: 1.0322 - val_accuracy: 0.6373\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0466 - accuracy: 0.6286 - val_loss: 1.0290 - val_accuracy: 0.6371\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0391 - accuracy: 0.6307 - val_loss: 1.0233 - val_accuracy: 0.6399\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0328 - accuracy: 0.6333 - val_loss: 1.0169 - val_accuracy: 0.6412\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0284 - accuracy: 0.6335 - val_loss: 1.0138 - val_accuracy: 0.6413\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0189 - accuracy: 0.6371 - val_loss: 1.0076 - val_accuracy: 0.6441\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0171 - accuracy: 0.6379 - val_loss: 1.0058 - val_accuracy: 0.6465\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0128 - accuracy: 0.6397 - val_loss: 1.0013 - val_accuracy: 0.6481\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0082 - accuracy: 0.6421 - val_loss: 0.9958 - val_accuracy: 0.6503\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.0018 - accuracy: 0.6445 - val_loss: 0.9942 - val_accuracy: 0.6524\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9947 - accuracy: 0.6474 - val_loss: 0.9914 - val_accuracy: 0.6540\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9940 - accuracy: 0.6481 - val_loss: 0.9884 - val_accuracy: 0.6537\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9878 - accuracy: 0.6504 - val_loss: 0.9846 - val_accuracy: 0.6546\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9846 - accuracy: 0.6507 - val_loss: 0.9853 - val_accuracy: 0.6552\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9793 - accuracy: 0.6520 - val_loss: 0.9807 - val_accuracy: 0.6560\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9743 - accuracy: 0.6540 - val_loss: 0.9787 - val_accuracy: 0.6583\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9749 - accuracy: 0.6538 - val_loss: 0.9744 - val_accuracy: 0.6583\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9661 - accuracy: 0.6579 - val_loss: 0.9721 - val_accuracy: 0.6598\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9672 - accuracy: 0.6575 - val_loss: 0.9693 - val_accuracy: 0.6596\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9621 - accuracy: 0.6572 - val_loss: 0.9685 - val_accuracy: 0.6602\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9565 - accuracy: 0.6606 - val_loss: 0.9656 - val_accuracy: 0.6623\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9541 - accuracy: 0.6618 - val_loss: 0.9637 - val_accuracy: 0.6624\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9519 - accuracy: 0.6628 - val_loss: 0.9616 - val_accuracy: 0.6635\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9485 - accuracy: 0.6643 - val_loss: 0.9613 - val_accuracy: 0.6628\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9481 - accuracy: 0.6641 - val_loss: 0.9590 - val_accuracy: 0.6640\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9426 - accuracy: 0.6645 - val_loss: 0.9571 - val_accuracy: 0.6649\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9422 - accuracy: 0.6653 - val_loss: 0.9548 - val_accuracy: 0.6652\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9388 - accuracy: 0.6691 - val_loss: 0.9534 - val_accuracy: 0.6673\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9360 - accuracy: 0.6692 - val_loss: 0.9531 - val_accuracy: 0.6669\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9347 - accuracy: 0.6687 - val_loss: 0.9524 - val_accuracy: 0.6665\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9332 - accuracy: 0.6709 - val_loss: 0.9497 - val_accuracy: 0.6658\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9303 - accuracy: 0.6729 - val_loss: 0.9496 - val_accuracy: 0.6683\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9275 - accuracy: 0.6722 - val_loss: 0.9469 - val_accuracy: 0.6683\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9277 - accuracy: 0.6725 - val_loss: 0.9465 - val_accuracy: 0.6684\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9249 - accuracy: 0.6729 - val_loss: 0.9451 - val_accuracy: 0.6697\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9233 - accuracy: 0.6737 - val_loss: 0.9424 - val_accuracy: 0.6695\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9186 - accuracy: 0.6756 - val_loss: 0.9422 - val_accuracy: 0.6683\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9189 - accuracy: 0.6750 - val_loss: 0.9415 - val_accuracy: 0.6699\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9219 - accuracy: 0.6738 - val_loss: 0.9402 - val_accuracy: 0.6706\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9180 - accuracy: 0.6765 - val_loss: 0.9390 - val_accuracy: 0.6716\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9159 - accuracy: 0.6752 - val_loss: 0.9391 - val_accuracy: 0.6726\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9125 - accuracy: 0.6763 - val_loss: 0.9375 - val_accuracy: 0.6726\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9109 - accuracy: 0.6764 - val_loss: 0.9366 - val_accuracy: 0.6713\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9092 - accuracy: 0.6791 - val_loss: 0.9379 - val_accuracy: 0.6718\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9112 - accuracy: 0.6796 - val_loss: 0.9357 - val_accuracy: 0.6718\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9076 - accuracy: 0.6798 - val_loss: 0.9361 - val_accuracy: 0.6738\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9078 - accuracy: 0.6783 - val_loss: 0.9360 - val_accuracy: 0.6744\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.9075 - accuracy: 0.6781 - val_loss: 0.9329 - val_accuracy: 0.6755\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9055 - accuracy: 0.6821 - val_loss: 0.9338 - val_accuracy: 0.6745\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9036 - accuracy: 0.6809 - val_loss: 0.9320 - val_accuracy: 0.6742\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9029 - accuracy: 0.6805 - val_loss: 0.9310 - val_accuracy: 0.6741\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8992 - accuracy: 0.6831 - val_loss: 0.9313 - val_accuracy: 0.6758\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.9001 - accuracy: 0.6816 - val_loss: 0.9303 - val_accuracy: 0.6755\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8966 - accuracy: 0.6829 - val_loss: 0.9313 - val_accuracy: 0.6751\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.9008 - accuracy: 0.6819 - val_loss: 0.9289 - val_accuracy: 0.6767\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8975 - accuracy: 0.6844 - val_loss: 0.9285 - val_accuracy: 0.6757\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8953 - accuracy: 0.6832 - val_loss: 0.9283 - val_accuracy: 0.6765\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8955 - accuracy: 0.6824 - val_loss: 0.9279 - val_accuracy: 0.6759\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8944 - accuracy: 0.6842 - val_loss: 0.9265 - val_accuracy: 0.6766\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.8945 - accuracy: 0.6835 - val_loss: 0.9270 - val_accuracy: 0.6756\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.8918 - accuracy: 0.6848 - val_loss: 0.9257 - val_accuracy: 0.6767\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8918 - accuracy: 0.6841 - val_loss: 0.9253 - val_accuracy: 0.6777\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8916 - accuracy: 0.6866 - val_loss: 0.9260 - val_accuracy: 0.6764\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8924 - accuracy: 0.6847 - val_loss: 0.9245 - val_accuracy: 0.6778\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8925 - accuracy: 0.6839 - val_loss: 0.9244 - val_accuracy: 0.6774\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8890 - accuracy: 0.6875 - val_loss: 0.9239 - val_accuracy: 0.6776\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8899 - accuracy: 0.6861 - val_loss: 0.9242 - val_accuracy: 0.6780\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.8900 - accuracy: 0.6841 - val_loss: 0.9239 - val_accuracy: 0.6775\n"
     ]
    }
   ],
   "source": [
    "initial_learning_rate = 1e-6\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "#訓練\n",
    "# compile  #在每層 layer 和 compile 都可自動尋找超參數\n",
    "\n",
    "MyNet.model.compile(\n",
    "    #learning_rate=0.01\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate=lr_schedule,epsilon=1e-09),\n",
    "    loss= 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit\n",
    "history  = \\\n",
    "MyNet.model.fit(\n",
    "    x = dataset.train_x,\n",
    "    y = dataset.train_y,\n",
    "    epochs = 100,\n",
    "    batch_size = 64,\n",
    "    validation_data = (dataset.test_x ,dataset.test_y)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./result/frank_AlexNet/CIFAR10/2021-10-13 02:20:02/model/assets\n",
      "saveModel... Done\n"
     ]
    }
   ],
   "source": [
    "#取得訓練結果\n",
    "#   save the entire model as a single file\n",
    "#   model = keras.models.load_model(\"path_to_my_model\")\n",
    "# model.save(f\"{save_model_dir}\")\n",
    "MyNet.outputHelper.saveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.2255520820617676,\n",
       "  1.9836751222610474,\n",
       "  1.8450367450714111,\n",
       "  1.7410557270050049,\n",
       "  1.654253602027893,\n",
       "  1.58892822265625,\n",
       "  1.5331717729568481,\n",
       "  1.4870978593826294,\n",
       "  1.4493645429611206,\n",
       "  1.4108284711837769,\n",
       "  1.3802162408828735,\n",
       "  1.3542932271957397,\n",
       "  1.32827889919281,\n",
       "  1.30370032787323,\n",
       "  1.2827106714248657,\n",
       "  1.2626243829727173,\n",
       "  1.244078516960144,\n",
       "  1.226934790611267,\n",
       "  1.207912802696228,\n",
       "  1.1905367374420166,\n",
       "  1.1807632446289062,\n",
       "  1.1648192405700684,\n",
       "  1.1519652605056763,\n",
       "  1.1404800415039062,\n",
       "  1.128990650177002,\n",
       "  1.1163259744644165,\n",
       "  1.1037863492965698,\n",
       "  1.0971717834472656,\n",
       "  1.0851019620895386,\n",
       "  1.0806281566619873,\n",
       "  1.0704725980758667,\n",
       "  1.0634857416152954,\n",
       "  1.0555565357208252,\n",
       "  1.0465997457504272,\n",
       "  1.0391113758087158,\n",
       "  1.0327526330947876,\n",
       "  1.0283869504928589,\n",
       "  1.0188812017440796,\n",
       "  1.0171078443527222,\n",
       "  1.0128209590911865,\n",
       "  1.0082406997680664,\n",
       "  1.0017788410186768,\n",
       "  0.9947259426116943,\n",
       "  0.993959903717041,\n",
       "  0.9878193140029907,\n",
       "  0.9846231937408447,\n",
       "  0.9792601466178894,\n",
       "  0.9742671847343445,\n",
       "  0.9749171733856201,\n",
       "  0.966136634349823,\n",
       "  0.9671845436096191,\n",
       "  0.9621134996414185,\n",
       "  0.9565216898918152,\n",
       "  0.9540548324584961,\n",
       "  0.9518837332725525,\n",
       "  0.9485464096069336,\n",
       "  0.9481481313705444,\n",
       "  0.9426143765449524,\n",
       "  0.9421520829200745,\n",
       "  0.9388371706008911,\n",
       "  0.9359895586967468,\n",
       "  0.9346734285354614,\n",
       "  0.933167576789856,\n",
       "  0.9302980303764343,\n",
       "  0.9274911880493164,\n",
       "  0.9276650547981262,\n",
       "  0.9248973727226257,\n",
       "  0.9232933521270752,\n",
       "  0.9185832142829895,\n",
       "  0.918931782245636,\n",
       "  0.9219011068344116,\n",
       "  0.9180383682250977,\n",
       "  0.915907084941864,\n",
       "  0.9125034213066101,\n",
       "  0.9108796715736389,\n",
       "  0.9092468023300171,\n",
       "  0.9111759662628174,\n",
       "  0.9075866341590881,\n",
       "  0.90784752368927,\n",
       "  0.9074754118919373,\n",
       "  0.9055429697036743,\n",
       "  0.9035657048225403,\n",
       "  0.9029461145401001,\n",
       "  0.8991992473602295,\n",
       "  0.9001179933547974,\n",
       "  0.8965966701507568,\n",
       "  0.9007503390312195,\n",
       "  0.8975159525871277,\n",
       "  0.8953109383583069,\n",
       "  0.8955141305923462,\n",
       "  0.8943692445755005,\n",
       "  0.8945260047912598,\n",
       "  0.8917626738548279,\n",
       "  0.8918065428733826,\n",
       "  0.8915503621101379,\n",
       "  0.8924499154090881,\n",
       "  0.8925039172172546,\n",
       "  0.8890400528907776,\n",
       "  0.8898583054542542,\n",
       "  0.889996349811554],\n",
       " 'accuracy': [0.16777999699115753,\n",
       "  0.2639400064945221,\n",
       "  0.3134399950504303,\n",
       "  0.34973999857902527,\n",
       "  0.383899986743927,\n",
       "  0.4090999960899353,\n",
       "  0.434579998254776,\n",
       "  0.45118001103401184,\n",
       "  0.46588000655174255,\n",
       "  0.4853000044822693,\n",
       "  0.4949199855327606,\n",
       "  0.5068600177764893,\n",
       "  0.5174999833106995,\n",
       "  0.5270199775695801,\n",
       "  0.5337799787521362,\n",
       "  0.5459399819374084,\n",
       "  0.5493199825286865,\n",
       "  0.5568600296974182,\n",
       "  0.5640599727630615,\n",
       "  0.5730999708175659,\n",
       "  0.5769799947738647,\n",
       "  0.5822799801826477,\n",
       "  0.5872399806976318,\n",
       "  0.5912799835205078,\n",
       "  0.5977799892425537,\n",
       "  0.6014800071716309,\n",
       "  0.6068800091743469,\n",
       "  0.6070399880409241,\n",
       "  0.6133800148963928,\n",
       "  0.6160600185394287,\n",
       "  0.6176999807357788,\n",
       "  0.6223199963569641,\n",
       "  0.6236600279808044,\n",
       "  0.6286399960517883,\n",
       "  0.6306999921798706,\n",
       "  0.6332600116729736,\n",
       "  0.6334999799728394,\n",
       "  0.6370999813079834,\n",
       "  0.6379200220108032,\n",
       "  0.6396999955177307,\n",
       "  0.6420999765396118,\n",
       "  0.6445199847221375,\n",
       "  0.6474199891090393,\n",
       "  0.648140013217926,\n",
       "  0.650439977645874,\n",
       "  0.6507400274276733,\n",
       "  0.6520400047302246,\n",
       "  0.6540200114250183,\n",
       "  0.6538199782371521,\n",
       "  0.6579399704933167,\n",
       "  0.6574599742889404,\n",
       "  0.6571800112724304,\n",
       "  0.6606199741363525,\n",
       "  0.6617799997329712,\n",
       "  0.6627600193023682,\n",
       "  0.6642799973487854,\n",
       "  0.6641200184822083,\n",
       "  0.6645399928092957,\n",
       "  0.6653000116348267,\n",
       "  0.6690599918365479,\n",
       "  0.669160008430481,\n",
       "  0.668720006942749,\n",
       "  0.6708800196647644,\n",
       "  0.6729000210762024,\n",
       "  0.67221999168396,\n",
       "  0.6724600195884705,\n",
       "  0.6729400157928467,\n",
       "  0.6736800074577332,\n",
       "  0.6756200194358826,\n",
       "  0.6749799847602844,\n",
       "  0.6737800240516663,\n",
       "  0.6765000224113464,\n",
       "  0.6752399802207947,\n",
       "  0.6762999892234802,\n",
       "  0.6764000058174133,\n",
       "  0.679099977016449,\n",
       "  0.6796000003814697,\n",
       "  0.6797599792480469,\n",
       "  0.6783400177955627,\n",
       "  0.678059995174408,\n",
       "  0.6820999979972839,\n",
       "  0.680899977684021,\n",
       "  0.6805400252342224,\n",
       "  0.6830999851226807,\n",
       "  0.6815800070762634,\n",
       "  0.6828799843788147,\n",
       "  0.6819199919700623,\n",
       "  0.6844000220298767,\n",
       "  0.6831600069999695,\n",
       "  0.6824399828910828,\n",
       "  0.6841999888420105,\n",
       "  0.6835200190544128,\n",
       "  0.6848400235176086,\n",
       "  0.6841199994087219,\n",
       "  0.6866199970245361,\n",
       "  0.684660017490387,\n",
       "  0.6838600039482117,\n",
       "  0.6875399947166443,\n",
       "  0.6861400008201599,\n",
       "  0.6840800046920776],\n",
       " 'val_loss': [2.020451545715332,\n",
       "  1.8186980485916138,\n",
       "  1.700201153755188,\n",
       "  1.6057655811309814,\n",
       "  1.5313079357147217,\n",
       "  1.4748084545135498,\n",
       "  1.4276500940322876,\n",
       "  1.3859697580337524,\n",
       "  1.3516396284103394,\n",
       "  1.3231240510940552,\n",
       "  1.3004993200302124,\n",
       "  1.2724913358688354,\n",
       "  1.256493330001831,\n",
       "  1.2337441444396973,\n",
       "  1.2137643098831177,\n",
       "  1.1979620456695557,\n",
       "  1.182409644126892,\n",
       "  1.1690484285354614,\n",
       "  1.1564842462539673,\n",
       "  1.14045250415802,\n",
       "  1.1286364793777466,\n",
       "  1.1170355081558228,\n",
       "  1.1093796491622925,\n",
       "  1.0998291969299316,\n",
       "  1.0901198387145996,\n",
       "  1.0807405710220337,\n",
       "  1.0709383487701416,\n",
       "  1.0622880458831787,\n",
       "  1.0594242811203003,\n",
       "  1.055646300315857,\n",
       "  1.046094298362732,\n",
       "  1.0374019145965576,\n",
       "  1.0321506261825562,\n",
       "  1.0289819240570068,\n",
       "  1.02329421043396,\n",
       "  1.016869306564331,\n",
       "  1.0137704610824585,\n",
       "  1.0075762271881104,\n",
       "  1.0057588815689087,\n",
       "  1.0013338327407837,\n",
       "  0.9958248138427734,\n",
       "  0.9942135810852051,\n",
       "  0.9913961887359619,\n",
       "  0.9884039759635925,\n",
       "  0.9846186637878418,\n",
       "  0.9853327870368958,\n",
       "  0.9807416200637817,\n",
       "  0.9787175059318542,\n",
       "  0.9743762016296387,\n",
       "  0.9720697402954102,\n",
       "  0.9692927002906799,\n",
       "  0.9684785008430481,\n",
       "  0.9655714631080627,\n",
       "  0.9636903405189514,\n",
       "  0.9616426825523376,\n",
       "  0.9613392353057861,\n",
       "  0.9590167999267578,\n",
       "  0.9571386575698853,\n",
       "  0.9547742009162903,\n",
       "  0.9534170031547546,\n",
       "  0.9530863165855408,\n",
       "  0.9524165987968445,\n",
       "  0.9496707320213318,\n",
       "  0.9495534300804138,\n",
       "  0.9468819499015808,\n",
       "  0.9464601278305054,\n",
       "  0.9451465010643005,\n",
       "  0.9424073100090027,\n",
       "  0.9422269463539124,\n",
       "  0.9414774179458618,\n",
       "  0.9402311444282532,\n",
       "  0.9390348792076111,\n",
       "  0.9390561580657959,\n",
       "  0.9374815225601196,\n",
       "  0.9366199374198914,\n",
       "  0.9379437565803528,\n",
       "  0.9357220530509949,\n",
       "  0.9360538125038147,\n",
       "  0.9359791278839111,\n",
       "  0.9328611493110657,\n",
       "  0.9337847828865051,\n",
       "  0.9320436716079712,\n",
       "  0.9309542179107666,\n",
       "  0.9312711954116821,\n",
       "  0.9302968978881836,\n",
       "  0.9313302040100098,\n",
       "  0.9288715124130249,\n",
       "  0.9284623861312866,\n",
       "  0.928335428237915,\n",
       "  0.9279312491416931,\n",
       "  0.9265114068984985,\n",
       "  0.9269505739212036,\n",
       "  0.9256711006164551,\n",
       "  0.925251841545105,\n",
       "  0.9259718060493469,\n",
       "  0.9245028495788574,\n",
       "  0.9244343042373657,\n",
       "  0.9239171743392944,\n",
       "  0.9242069125175476,\n",
       "  0.9239029288291931],\n",
       " 'val_accuracy': [0.29100000858306885,\n",
       "  0.3529999852180481,\n",
       "  0.3935000002384186,\n",
       "  0.4242999851703644,\n",
       "  0.4514999985694885,\n",
       "  0.46299999952316284,\n",
       "  0.4837000072002411,\n",
       "  0.4977000057697296,\n",
       "  0.5087000131607056,\n",
       "  0.5189999938011169,\n",
       "  0.5268999934196472,\n",
       "  0.5371999740600586,\n",
       "  0.5429999828338623,\n",
       "  0.5526000261306763,\n",
       "  0.5609999895095825,\n",
       "  0.5695000290870667,\n",
       "  0.5730999708175659,\n",
       "  0.5809999704360962,\n",
       "  0.5863000154495239,\n",
       "  0.5910000205039978,\n",
       "  0.5963000059127808,\n",
       "  0.5992000102996826,\n",
       "  0.6054999828338623,\n",
       "  0.6064000129699707,\n",
       "  0.6122000217437744,\n",
       "  0.6115999817848206,\n",
       "  0.619700014591217,\n",
       "  0.6209999918937683,\n",
       "  0.6212000250816345,\n",
       "  0.6244999766349792,\n",
       "  0.6290000081062317,\n",
       "  0.6313999891281128,\n",
       "  0.6373000144958496,\n",
       "  0.6370999813079834,\n",
       "  0.6399000287055969,\n",
       "  0.6412000060081482,\n",
       "  0.6413000226020813,\n",
       "  0.64410001039505,\n",
       "  0.6464999914169312,\n",
       "  0.6481000185012817,\n",
       "  0.6503000259399414,\n",
       "  0.652400016784668,\n",
       "  0.6539999842643738,\n",
       "  0.6536999940872192,\n",
       "  0.6546000242233276,\n",
       "  0.6552000045776367,\n",
       "  0.656000018119812,\n",
       "  0.65829998254776,\n",
       "  0.65829998254776,\n",
       "  0.6597999930381775,\n",
       "  0.659600019454956,\n",
       "  0.6601999998092651,\n",
       "  0.6622999906539917,\n",
       "  0.6624000072479248,\n",
       "  0.6635000109672546,\n",
       "  0.6628000140190125,\n",
       "  0.6639999747276306,\n",
       "  0.664900004863739,\n",
       "  0.6651999950408936,\n",
       "  0.6672999858856201,\n",
       "  0.6668999791145325,\n",
       "  0.6664999723434448,\n",
       "  0.6657999753952026,\n",
       "  0.6682999730110168,\n",
       "  0.6682999730110168,\n",
       "  0.66839998960495,\n",
       "  0.669700026512146,\n",
       "  0.6694999933242798,\n",
       "  0.6682999730110168,\n",
       "  0.6699000000953674,\n",
       "  0.6705999970436096,\n",
       "  0.6715999841690063,\n",
       "  0.6725999712944031,\n",
       "  0.6725999712944031,\n",
       "  0.6712999939918518,\n",
       "  0.6718000173568726,\n",
       "  0.6718000173568726,\n",
       "  0.673799991607666,\n",
       "  0.6743999719619751,\n",
       "  0.6754999756813049,\n",
       "  0.6744999885559082,\n",
       "  0.6741999983787537,\n",
       "  0.6740999817848206,\n",
       "  0.6758000254631042,\n",
       "  0.6754999756813049,\n",
       "  0.6751000285148621,\n",
       "  0.6766999959945679,\n",
       "  0.6757000088691711,\n",
       "  0.6765000224113464,\n",
       "  0.6758999824523926,\n",
       "  0.6765999794006348,\n",
       "  0.675599992275238,\n",
       "  0.6766999959945679,\n",
       "  0.6776999831199646,\n",
       "  0.6764000058174133,\n",
       "  0.6777999997138977,\n",
       "  0.6773999929428101,\n",
       "  0.6776000261306763,\n",
       "  0.6779999732971191,\n",
       "  0.6775000095367432]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6650/270881836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(history.history)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMyNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputHelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawTrainProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/keras_frank/KerasPractice/utils/outputs.py\u001b[0m in \u001b[0;36mdrawTrainProcess\u001b[0;34m(self, history)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         self. __pltOnePlot('loss' ,(1,2,1),\n\u001b[1;32m     47\u001b[0m         [\n",
      "\u001b[0;32m~/Documents/keras_frank/KerasPractice/utils/outputs.py\u001b[0m in \u001b[0;36m__pltOnePlot\u001b[0;34m(self, title, pos, plotDatas)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mxticks_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mxticks_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0myticks_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0myticks_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(history.history)\n",
    "r = history.history\n",
    "MyNet.outputHelper.drawTrainProcess(r)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15443c155933cd13719346cff95e6995c74e568d18bfff688e9267bd1dcf0534"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('keras2.6': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
